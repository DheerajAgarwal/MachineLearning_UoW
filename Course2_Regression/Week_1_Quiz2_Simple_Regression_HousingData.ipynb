{
 cells [
  {
   cell_type markdown,
   metadata {},
   source [
    # Regression Week 1 Simple Linear Regression
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    In this notebook we will use data on house sales in King County to predict house prices using simple (one input) linear regression. You willn,
    n,
     Compute important summary statistics on the complete data set (using `graphlab SArray` and `SFrame` functions or any other modules)n,
     Write a function to compute the Simple Linear Regression weights using the closed form solutionn,
     Write a function to make predictions of the output given the input featuren,
     Turn the regression around to predict the input given the outputn,
     Compare two different models for predicting house pricesn,
    n,
    In this notebook you will be provided with some already complete code as well as some code that you should complete yourself in order to answer quiz questions. The code we provide to complete is optional and is there to assist you with solving the problems but feel free to ignore the helper code and write your own.n,
    n,
    When using `pandas`, there is no need to load the housing data as the train and the test data are provided as part of the course. This was done to avoid the random seed creating issue in split as the quiz answers are based on that.
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    ## Modules
   ]
  },
  {
   cell_type code,
   execution_count 1,
   metadata {
    collapsed false
   },
   outputs [],
   source [
    # import graphlabn,
    n,
    import pandas as pdn,
    import numpy as np
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    ## Get Datan,
    n,
    Dataset is from house sales in King County, the region where the city of Seattle, WA is located.
   ]
  },
  {
   cell_type code,
   execution_count 2,
   metadata {
    collapsed false
   },
   outputs [],
   source [
    # sales = graphlab.SFrame('kc_house_data.gl')n,
    sales = pd.read_csv(.datakc_house_train_data.csv)n,
    train_data = pd.read_csv(.datakc_house_train_data.csv)n,
    test_data = pd.read_csv(.datakc_house_test_data.csv)
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    ## Summary Statistics
   ]
  },
  {
   cell_type code,
   execution_count 3,
   metadata {
    collapsed false
   },
   outputs [
    {
     data {
      textplain [
       (17384, 21)
      ]
     },
     execution_count 3,
     metadata {},
     output_type execute_result
    }
   ],
   source [
    sales.shape
   ]
  },
  {
   cell_type code,
   execution_count 4,
   metadata {
    collapsed false
   },
   outputs [
    {
     data {
      textplain [
       Index([u'id', u'date', u'price', u'bedrooms', u'bathrooms', u'sqft_living',n,
              u'sqft_lot', u'floors', u'waterfront', u'view', u'condition', u'grade',n,
              u'sqft_above', u'sqft_basement', u'yr_built', u'yr_renovated',n,
              u'zipcode', u'lat', u'long', u'sqft_living15', u'sqft_lot15'],n,
             dtype='object')
      ]
     },
     execution_count 4,
     metadata {},
     output_type execute_result
    }
   ],
   source [
    sales.columns
   ]
  },
  {
   cell_type code,
   execution_count 5,
   metadata {
    collapsed false
   },
   outputs [
    {
     data {
      textplain [
       id                 int64n,
       date              objectn,
       price            float64n,
       bedrooms           int64n,
       bathrooms        float64n,
       sqft_living        int64n,
       sqft_lot           int64n,
       floors           float64n,
       waterfront         int64n,
       view               int64n,
       condition          int64n,
       grade              int64n,
       sqft_above         int64n,
       sqft_basement      int64n,
       yr_built           int64n,
       yr_renovated       int64n,
       zipcode            int64n,
       lat              float64n,
       long             float64n,
       sqft_living15      int64n,
       sqft_lot15         int64n,
       dtype object
      ]
     },
     execution_count 5,
     metadata {},
     output_type execute_result
    }
   ],
   source [
    sales.dtypes
   ]
  },
  {
   cell_type code,
   execution_count 6,
   metadata {
    collapsed false
   },
   outputs [
    {
     data {
      texthtml [
       divn,
       table border=1 class=dataframen,
         theadn,
           tr style=text-align right;n,
             ththn,
             thidthn,
             thpricethn,
             thbedroomsthn,
             thbathroomsthn,
             thsqft_livingthn,
             thsqft_lotthn,
             thfloorsthn,
             thwaterfrontthn,
             thviewthn,
             thconditionthn,
             thgradethn,
             thsqft_abovethn,
             thsqft_basementthn,
             thyr_builtthn,
             thyr_renovatedthn,
             thzipcodethn,
             thlatthn,
             thlongthn,
             thsqft_living15thn,
             thsqft_lot15thn,
           trn,
         theadn,
         tbodyn,
           trn,
             thcountthn,
             td1.738400e+04tdn,
             td1.738400e+04tdn,
             td17384.000000tdn,
             td17384.000000tdn,
             td17384.000000tdn,
             td1.738400e+04tdn,
             td17384.000000tdn,
             td17384.000000tdn,
             td17384.000000tdn,
             td17384.000000tdn,
             td17384.000000tdn,
             td17384.000000tdn,
             td17384.000000tdn,
             td17384.000000tdn,
             td17384.000000tdn,
             td17384.000000tdn,
             td17384.000000tdn,
             td17384.000000tdn,
             td17384.000000tdn,
             td17384.000000tdn,
           trn,
           trn,
             thmeanthn,
             td4.574349e+09tdn,
             td5.393666e+05tdn,
             td3.369363tdn,
             td2.115048tdn,
             td2080.029510tdn,
             td1.509191e+04tdn,
             td1.494248tdn,
             td0.007651tdn,
             td0.236079tdn,
             td3.410780tdn,
             td7.655028tdn,
             td1787.844512tdn,
             td292.184998tdn,
             td1971.152727tdn,
             td83.107973tdn,
             td98077.936896tdn,
             td47.559313tdn,
             td-122.213281tdn,
             td1985.994995tdn,
             td12776.380867tdn,
           trn,
           trn,
             thstdthn,
             td2.872356e+09tdn,
             td3.696912e+05tdn,
             td0.906468tdn,
             td0.771783tdn,
             td921.630888tdn,
             td4.145927e+04tdn,
             td0.539443tdn,
             td0.087136tdn,
             td0.768008tdn,
             td0.649792tdn,
             td1.169818tdn,
             td827.107595tdn,
             td444.404136tdn,
             td29.328722tdn,
             td398.692283tdn,
             td53.525617tdn,
             td0.138703tdn,
             td0.140906tdn,
             td686.512835tdn,
             td27175.730523tdn,
           trn,
           trn,
             thminthn,
             td1.000102e+06tdn,
             td7.500000e+04tdn,
             td0.000000tdn,
             td0.000000tdn,
             td290.000000tdn,
             td5.200000e+02tdn,
             td1.000000tdn,
             td0.000000tdn,
             td0.000000tdn,
             td1.000000tdn,
             td1.000000tdn,
             td290.000000tdn,
             td0.000000tdn,
             td1900.000000tdn,
             td0.000000tdn,
             td98001.000000tdn,
             td47.159300tdn,
             td-122.519000tdn,
             td399.000000tdn,
             td651.000000tdn,
           trn,
           trn,
             th25%thn,
             td2.124087e+09tdn,
             td3.200000e+05tdn,
             td3.000000tdn,
             td1.750000tdn,
             td1420.000000tdn,
             td5.049500e+03tdn,
             td1.000000tdn,
             td0.000000tdn,
             td0.000000tdn,
             td3.000000tdn,
             td7.000000tdn,
             td1200.000000tdn,
             td0.000000tdn,
             td1952.000000tdn,
             td0.000000tdn,
             td98033.000000tdn,
             td47.468650tdn,
             td-122.328000tdn,
             td1490.000000tdn,
             td5100.000000tdn,
           trn,
           trn,
             th50%thn,
             td3.892800e+09tdn,
             td4.500000e+05tdn,
             td3.000000tdn,
             td2.250000tdn,
             td1910.000000tdn,
             td7.616000e+03tdn,
             td1.500000tdn,
             td0.000000tdn,
             td0.000000tdn,
             td3.000000tdn,
             td7.000000tdn,
             td1560.000000tdn,
             td0.000000tdn,
             td1975.000000tdn,
             td0.000000tdn,
             td98065.000000tdn,
             td47.571400tdn,
             td-122.229000tdn,
             td1840.000000tdn,
             td7620.000000tdn,
           trn,
           trn,
             th75%thn,
             td7.304301e+09tdn,
             td6.400000e+05tdn,
             td4.000000tdn,
             td2.500000tdn,
             td2550.000000tdn,
             td1.066525e+04tdn,
             td2.000000tdn,
             td0.000000tdn,
             td0.000000tdn,
             td4.000000tdn,
             td8.000000tdn,
             td2210.000000tdn,
             td560.000000tdn,
             td1997.000000tdn,
             td0.000000tdn,
             td98117.000000tdn,
             td47.677625tdn,
             td-122.125000tdn,
             td2360.000000tdn,
             td10065.250000tdn,
           trn,
           trn,
             thmaxthn,
             td9.900000e+09tdn,
             td7.700000e+06tdn,
             td10.000000tdn,
             td8.000000tdn,
             td13540.000000tdn,
             td1.651359e+06tdn,
             td3.500000tdn,
             td1.000000tdn,
             td4.000000tdn,
             td5.000000tdn,
             td13.000000tdn,
             td9410.000000tdn,
             td4820.000000tdn,
             td2015.000000tdn,
             td2015.000000tdn,
             td98199.000000tdn,
             td47.777600tdn,
             td-121.315000tdn,
             td6210.000000tdn,
             td871200.000000tdn,
           trn,
         tbodyn,
       tablen,
       div
      ],
      textplain [
                        id         price      bedrooms     bathrooms   sqft_living  n,
       count  1.738400e+04  1.738400e+04  17384.000000  17384.000000  17384.000000   n,
       mean   4.574349e+09  5.393666e+05      3.369363      2.115048   2080.029510   n,
       std    2.872356e+09  3.696912e+05      0.906468      0.771783    921.630888   n,
       min    1.000102e+06  7.500000e+04      0.000000      0.000000    290.000000   n,
       25%    2.124087e+09  3.200000e+05      3.000000      1.750000   1420.000000   n,
       50%    3.892800e+09  4.500000e+05      3.000000      2.250000   1910.000000   n,
       75%    7.304301e+09  6.400000e+05      4.000000      2.500000   2550.000000   n,
       max    9.900000e+09  7.700000e+06     10.000000      8.000000  13540.000000   n,
       n,
                  sqft_lot        floors    waterfront          view     condition  n,
       count  1.738400e+04  17384.000000  17384.000000  17384.000000  17384.000000   n,
       mean   1.509191e+04      1.494248      0.007651      0.236079      3.410780   n,
       std    4.145927e+04      0.539443      0.087136      0.768008      0.649792   n,
       min    5.200000e+02      1.000000      0.000000      0.000000      1.000000   n,
       25%    5.049500e+03      1.000000      0.000000      0.000000      3.000000   n,
       50%    7.616000e+03      1.500000      0.000000      0.000000      3.000000   n,
       75%    1.066525e+04      2.000000      0.000000      0.000000      4.000000   n,
       max    1.651359e+06      3.500000      1.000000      4.000000      5.000000   n,
       n,
                     grade    sqft_above  sqft_basement      yr_built  yr_renovated  n,
       count  17384.000000  17384.000000   17384.000000  17384.000000  17384.000000   n,
       mean       7.655028   1787.844512     292.184998   1971.152727     83.107973   n,
       std        1.169818    827.107595     444.404136     29.328722    398.692283   n,
       min        1.000000    290.000000       0.000000   1900.000000      0.000000   n,
       25%        7.000000   1200.000000       0.000000   1952.000000      0.000000   n,
       50%        7.000000   1560.000000       0.000000   1975.000000      0.000000   n,
       75%        8.000000   2210.000000     560.000000   1997.000000      0.000000   n,
       max       13.000000   9410.000000    4820.000000   2015.000000   2015.000000   n,
       n,
                   zipcode           lat          long  sqft_living15     sqft_lot15  n,
       count  17384.000000  17384.000000  17384.000000   17384.000000   17384.000000  n,
       mean   98077.936896     47.559313   -122.213281    1985.994995   12776.380867  n,
       std       53.525617      0.138703      0.140906     686.512835   27175.730523  n,
       min    98001.000000     47.159300   -122.519000     399.000000     651.000000  n,
       25%    98033.000000     47.468650   -122.328000    1490.000000    5100.000000  n,
       50%    98065.000000     47.571400   -122.229000    1840.000000    7620.000000  n,
       75%    98117.000000     47.677625   -122.125000    2360.000000   10065.250000  n,
       max    98199.000000     47.777600   -121.315000    6210.000000  871200.000000  
      ]
     },
     execution_count 6,
     metadata {},
     output_type execute_result
    }
   ],
   source [
    sales.describe()
   ]
  },
  {
   cell_type markdown,
   metadata {
    collapsed false
   },
   source [
    #### Split data into training and testing - needed only for graphlab createn,
    n,
    We use seed=0 so that everyone running this notebook gets the same results.  In practice, you may set a random seed (or let GraphLab Create pick a random seed for you). n,
    n,
        train_data,test_data = sales.random_split(.8,seed=0)
   ]
  },
  {
   cell_type code,
   execution_count 7,
   metadata {
    collapsed false
   },
   outputs [
    {
     name stdout,
     output_type stream,
     text [
      average price via method 1 539366.627934n,
      average price via method 2 539366.627934n
     ]
    }
   ],
   source [
    # Let's compute the mean of the House Prices in King County in 2 different ways.n,
    prices = sales['price'] # extract the price columnn,
    n,
    # recall that the arithmetic average (the mean) is the sum of the prices divided by the total number of housesn,
    sum_prices = prices.sum()n,
    num_houses = prices.size # .size() when using SArraysn,
    avg_price_1 = sum_pricesnum_housesn,
    avg_price_2 = prices.mean() # if you just want the average, the .mean() functionn,
    print average price via method 1  + str(avg_price_1)n,
    print average price via method 2  + str(avg_price_2)
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    As we see we get the same answer both ways
   ]
  },
  {
   cell_type code,
   execution_count 8,
   metadata {
    collapsed false
   },
   outputs [
    {
     name stdout,
     output_type stream,
     text [
      the sum of price squared with scientific notation is 7.43305185234e+15n,
      the sum of price squared without scientific notation is 7433051852335772.000000n
     ]
    }
   ],
   source [
    # Let's compute the sum of squares of price. We can multiply two SArrays of the same length elementwise also with n,
    prices_squared = pricespricesn,
    sum_prices_squared = prices_squared.sum() # price_squared is an SArray of the squares and we want to add them up.n,
    print the sum of price squared with scientific notation is  + str(sum_prices_squared)n,
    print the sum of price squared without scientific notation is  + str('{0f}'.format(sum_prices_squared))
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    Aside The python notation x.xxe+yy means x.xx  10^(yy). e.g 100 = 10^2 = 110^2 = 1e2 
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    ## Build a generic simple linear regression function 
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    We can use the closed form solution found from lecture to compute the slope and intercept for a simple linear regression on observations input_feature, output.n,
    n,
    Complete the following function (or write your own) to compute the simple linear regression slope and intercept
   ]
  },
  {
   cell_type code,
   execution_count 9,
   metadata {
    collapsed false
   },
   outputs [],
   source [
    def simple_linear_regression(X, Y)n,
        n,
        n,
        X is the input featuren,
        Y is the outputn,
        small caps in the formula represent means.n,
        n,
        n,
        # compute the mean of input_feature and outputn,
        x = X.mean()n,
        y = Y.mean()n,
        n,
        # compute the product of the output and the input_feature and then take its meann,
        XY =  X  Yn,
        xy = XY.mean()n,
        n,
        # compute the squared value of the input_feature and its meann,
        sq_X = X  2n,
        sq_x = sq_X.mean()n,
        n,
        numerator = xy - (x  y)n,
        denominator = sq_x - (x  x)n,
        n,
        # use the formula for the slopen,
        slope = numerator  denominatorn,
    n,
        # use the formula for the interceptn,
        intercept = y - slope  xn,
        n,
        return (intercept, slope)
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    We can test that our function works by passing it something where we know the answer. In particular we can generate a feature and then put the output exactly on a line output = 1 + 1input_feature then we know both our slope and intercept should be 1
   ]
  },
  {
   cell_type code,
   execution_count 10,
   metadata {
    collapsed false
   },
   outputs [
    {
     name stdout,
     output_type stream,
     text [
      Intercept 1.0n,
      Slope 1.0n
     ]
    }
   ],
   source [
    # test_feature = graphlab.SArray(range(5))n,
    # test_output = graphlab.SArray(1 + 1test_feature)n,
    test_feature = pd.Series(range(5))n,
    test_output = (1 + test_feature)n,
    n,
    (test_intercept, test_slope) =  simple_linear_regression(test_feature, test_output)n,
    print Intercept  + str(test_intercept)n,
    print Slope  + str(test_slope)
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    Now that we know it works let's build a regression model for predicting price based on sqft_living. Rembember that we train on train_data!
   ]
  },
  {
   cell_type code,
   execution_count 11,
   metadata {
    collapsed false
   },
   outputs [
    {
     name stdout,
     output_type stream,
     text [
      Intercept -47116.0790729n,
      Slope 281.95883963n
     ]
    }
   ],
   source [
    sqft_intercept, sqft_slope = simple_linear_regression(train_data['sqft_living'], train_data['price'])n,
    n,
    print Intercept  + str(sqft_intercept)n,
    print Slope  + str(sqft_slope)
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    ### Predicting Values
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    Now that we have the model parameters `intercept` & `slope` we can make predictions. Using SArrays it's easy to multiply an SArray by a constant and add a constant value. Complete the following function to return the predicted output given the input_feature, slope and intercept
   ]
  },
  {
   cell_type code,
   execution_count 12,
   metadata {
    collapsed false
   },
   outputs [],
   source [
    def get_regression_predictions(X, w0, w1)n,
        n,
        X is the input featuren,
        w0 is the intercept consistent with the notation in the lecturesn,
        w1 is the intercept consistent with the notation in the lecturesn,
        n,
        # calculate the predicted valuesn,
        n,
        y_pred = w0 + (w1X)n,
        n,
        return y_pred
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    Now that we can calculate a prediction given the slope and intercept let's make a prediction. Use (or alter) the following to find out the estimated price for a house with 2650 squarefeet according to the squarefeet model we estiamted above.n,
    n,
    ## Quiz Question 1n,
    n,
    Using your Slope and Intercept from (4), What is the predicted price for a house with 2650 sqft
   ]
  },
  {
   cell_type code,
   execution_count 13,
   metadata {
    collapsed false
   },
   outputs [
    {
     name stdout,
     output_type stream,
     text [
      The estimated price for a house with 2650 squarefeet is $700074.85n
     ]
    }
   ],
   source [
    my_house_sqft = 2650n,
    estimated_price = get_regression_predictions(my_house_sqft, sqft_intercept, sqft_slope)n,
    print The estimated price for a house with %d squarefeet is $%.2f % (my_house_sqft, estimated_price)
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    # Residual Sum of Squares
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    Now that we have a model and can make predictions let's evaluate our model using Residual Sum of Squares (RSS). Recall that RSS is the sum of the squares of the residuals and the residuals is just a fancy word for the difference between the predicted output and the true output. n,
    n,
    Complete the following (or write your own) function to compute the RSS of a simple linear regression model given the input_feature, output, intercept and slope
   ]
  },
  {
   cell_type code,
   execution_count 14,
   metadata {
    collapsed true
   },
   outputs [],
   source [
    def get_residual_sum_of_squares(X, Y, w0, w1)n,
        n,
        X is the input featuren,
        Y is the actual valuen,
        w0 is the intercept consistent with the notation in the lecturesn,
        w1 is the intercept consistent with the notation in the lecturesn,
        n,
        # First get the predictionsn,
        y_pred = w0 + (w1X)n,
    n,
        # then compute the residuals (since we are squaring it doesn't matter which order you subtract)n,
        error = y_pred - Yn,
    n,
        # square the residuals and add them upn,
        RSS = (error  2).sum()n,
    n,
        return(RSS)
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    Let's test our get_residual_sum_of_squares function by applying it to the test model where the data lie exactly on a line. Since they lie exactly on a line the residual sum of squares should be zero!
   ]
  },
  {
   cell_type code,
   execution_count 15,
   metadata {
    collapsed false
   },
   outputs [
    {
     name stdout,
     output_type stream,
     text [
      0.0n
     ]
    }
   ],
   source [
    print get_residual_sum_of_squares(test_feature, test_output, test_intercept, test_slope) # should be 0.0
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    Now use your function to calculate the RSS on training data from the squarefeet model calculated above.n,
    n,
    ## Quiz Question 2 n,
    n,
    According to this function and the slope and intercept from the squarefeet model What is the RSS for the simple linear regression using squarefeet to predict prices on TRAINING data
   ]
  },
  {
   cell_type code,
   execution_count 16,
   metadata {
    collapsed false
   },
   outputs [
    {
     name stdout,
     output_type stream,
     text [
      The RSS of predicting Prices based on Square Feet is  1.20191835418e+15n
     ]
    }
   ],
   source [
    rss_prices_on_sqft = get_residual_sum_of_squares(n,
        train_data['sqft_living'],n,
        train_data['price'],n,
        sqft_intercept,n,
        sqft_slope)n,
    n,
    print 'The RSS of predicting Prices based on Square Feet is  ' + str(rss_prices_on_sqft)
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    ### Predict the squarefeet given price
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    What if we want to predict the squarefoot given the price n,
    n,
    Since we have an equation y = a + bx we can solve the function for x. So that if we have the intercept (a) and the slope (b) and the price (y) we can solve for the estimated squarefeet (x).n,
    n,
    Complete the following function to compute the inverse regression estimate, i.e. predict the input_feature given the output.
   ]
  },
  {
   cell_type code,
   execution_count 17,
   metadata {
    collapsed true
   },
   outputs [],
   source [
    def inverse_regression_predictions(output, intercept, slope)n,
        # solve output = intercept + slopeinput_feature for input_feature. Use this equation to compute the inverse predictionsn,
        n,
        estimated_feature = (output - intercept)  slopen,
        return estimated_feature
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    Now that we have a function to compute the squarefeet given the price from our simple regression model let's see how big we might expect a house that costs $800,000 to be.n,
    n,
    ## Quiz Question 3n,
    n,
    According to this function and the regression slope and intercept from (3) what is the estimated square-feet for a house costing $800,000
   ]
  },
  {
   cell_type code,
   execution_count 18,
   metadata {
    collapsed false
   },
   outputs [
    {
     name stdout,
     output_type stream,
     text [
      The estimated squarefeet for a house worth $800000.00 is 3004n
     ]
    }
   ],
   source [
    my_house_price = 800000n,
    estimated_squarefeet = inverse_regression_predictions(my_house_price, sqft_intercept, sqft_slope)n,
    print The estimated squarefeet for a house worth $%.2f is %d % (my_house_price, estimated_squarefeet)
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    ## New Model estimate prices from bedrooms
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    We have made one model for predicting house prices using squarefeet, but there are many other features in the sales SFrame. n,
    Use your simple linear regression function to estimate the regression parameters from predicting Prices based on number of bedrooms. Use the training data!
   ]
  },
  {
   cell_type code,
   execution_count 19,
   metadata {
    collapsed false
   },
   outputs [
    {
     name stdout,
     output_type stream,
     text [
      Intercept 109473.177623n,
      Slope 127588.952934n
     ]
    }
   ],
   source [
    # Estimate the slope and intercept for predicting 'price' based on 'bedrooms'n,
    n,
    bed_intercept, bed_slope = simple_linear_regression(train_data['bedrooms'], train_data['price'])n,
    print Intercept  + str(bed_intercept)n,
    print Slope  + str(bed_slope)
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    # Test your Linear Regression Algorithm
   ]
  },
  {
   cell_type markdown,
   metadata {},
   source [
    Now we have two models for predicting the price of a house. How do we know which one is better Calculate the RSS on the TEST data (remember this data wasn't involved in learning the model). Compute the RSS from predicting prices using bedrooms and from predicting prices using squarefeet.n,
    n,
    ## Quiz Question 4n,
    n,
    Which model (square feet or bedrooms) has lowest RSS on TEST data Think about why this might be the case.
   ]
  },
  {
   cell_type code,
   execution_count 20,
   metadata {
    collapsed false
   },
   outputs [
    {
     name stdout,
     output_type stream,
     text [
      4.9059714283e+14n
     ]
    }
   ],
   source [
    # Compute RSS when using bedrooms on TEST datan,
    n,
    n,
    bed_intercept, bed_slope = simple_linear_regression(test_data['bedrooms'], test_data['price'])n,
    print get_residual_sum_of_squares(test_data['bedrooms'], test_data['price'], bed_intercept, bed_slope)n
   ]
  },
  {
   cell_type code,
   execution_count 21,
   metadata {
    collapsed false
   },
   outputs [
    {
     name stdout,
     output_type stream,
     text [
      2.751685739e+14n
     ]
    }
   ],
   source [
    # Compute RSS when using squarefeet on TEST datan,
    n,
    sqft_intercept, sqft_slope = simple_linear_regression(test_data['sqft_living'], test_data['price'])n,
    print get_residual_sum_of_squares(test_data['sqft_living'], test_data['price'], sqft_intercept, sqft_slope)n
   ]
  }
 ],
 metadata {
  anaconda-cloud {},
  kernelspec {
   display_name Python [conda envgl-env],
   language python,
   name conda-env-gl-env-py
  },
  language_info {
   codemirror_mode {
    name ipython,
    version 2
   },
   file_extension .py,
   mimetype textx-python,
   name python,
   nbconvert_exporter python,
   pygments_lexer ipython2,
   version 2.7.12
  }
 },
 nbformat 4,
 nbformat_minor 0
}